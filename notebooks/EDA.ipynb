{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FinTech Intelligent Document Processing â€” Exploratory Data Analysis\n",
    "\n",
    "This notebook explores the synthetic dataset used for document classification.\n",
    "\n",
    "**Tasks:**\n",
    "- Dataset inspection\n",
    "- Class distribution analysis\n",
    "- Text length analysis\n",
    "- Sample preview\n",
    "- Model readiness checks\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "sns.set(style=\"whitegrid\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Load Dataset"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df = pd.read_csv('../pipeline/data/final_dataset.csv')\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Class Distribution"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "sns.countplot(x=df['label'])\n",
    "plt.title('Document Class Distribution')\n",
    "plt.xticks(rotation=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Text Length Distribution"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df['text_length'] = df['text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.histplot(df['text_length'], bins=30, kde=True)\n",
    "plt.title('Text Length Distribution')\n",
    "plt.xlabel('Words per document')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Average Length per Class"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df.groupby('label')['text_length'].mean().sort_values().plot(kind='bar', figsize=(7,4))\n",
    "plt.title('Average Text Length by Class')\n",
    "plt.ylabel('Words')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Sample Documents"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for label in df['label'].unique():\n",
    "    print(f\"\\n--- {label.upper()} ---\")\n",
    "    print(df[df['label']==label].iloc[0]['text'])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Data Quality Checks"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"Missing values:\\n\", df.isnull().sum())\n",
    "print(\"Duplicate rows:\", df.duplicated().sum())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Dataset is balanced across 5 document classes\n",
    "- Text lengths are consistent across categories\n",
    "- No missing or duplicate values\n",
    "- Ready for classical ML and deep learning pipelines\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
